\chapter{Intelligenza artificiale e strategia dei dati}

Il possesso di una grande quantità di dati è il presupposto sulla base del quale possono essere sviluppati sistemi di intelligenza artificiale.
Quando parliamo di intelligenza artificiale dobbiamo considerare quello che era ieri e quello che è oggi e poi passeremo al tema della strategia dei dati.
Quando parliamo di intelligenza artificiale, dobbiamo immaginare che non si tratta di qualcosa di nuovo, ma di qualcosa su cui si è iniziato a ragionare negli anni 50 del 20° secolo.
Allan Turing, uno scienziato che nel 1950 pubblicò un articolo dal titolo Computing Machinery and Intelligence, nel quale si pose la domanda se le macchine potessero pensare.
Questo ha portato con sé una seconda domanda, ovvero che cosa significa pensare.
Poi ancora la domanda se fosse possibile realizzare delle macchine che possono imitare l'essere umano così da ingannarlo.

Quindi si spostò l'attenzione dal pensiero della macchina alla possibilità per la macchina di ingannare l'essere umano tanto da convincerlo di avere un'interlocuzione con un altro essere umano.
Oggi, a 70 anni di distanza, abbiamo dei sistemi della cosiddetta intelligenza artificiale generativa che interagiscono con una vera e propria conversazione con l'essere umano, con una forma di dialogo e la tecnologia con cui sono realizzate consente di rispondere a delle domande, ragionando e aggiornando le risposte alle domande in base alla conversazione con l'essere umano.
Stiamo parlando delle varie CHAT GPT e tutti i suoi fratelli, GBART, Gemini, Perplexity, cioè tutti strumenti che hanno le stesse possibilità.

Quindi al di là della padronanza del linguaggio, questo tipo di sistemi possono risolvere dei compiti nuovi e difficili che vanno dalla matematica alla programmazione, alla visione, alla medicina e quant'altro.
E le prestazioni di questi sistemi sono effettivamente molto vicine a quelle di livello umano.
A fianco alle possibilità che offre la tecnologia si è sviluppato anche un dibattito estremamente articolato in cui il tema che ci si pone è se sia giusto utilizzare questo tipo di sistemi, se questo tipo di sistemi possano essere un pericolo per l'essere umano e se sia necessario introdurre una regolamentazione o comunque prevedere che questi sistemi abbiano in qualche modo dei principi etici.
E quindi abbiamo un dibattito in cui da un lato abbiamo di recente avuto l'assegnazione del Nobel per la Fisica a chi ha fatto le ultime scoperte in materia di intelligenza artificiale, il premio dato a Hopefield e Hinton per aver messo le basi dell'intelligenza artificiale.
Dall'altra parte abbiamo teologi, filosofi e giuristi che dibattono proprio per cercare di comprendere, per segnalare la necessità che l'essere umano rimanga al centro dell'attenzione e che danno delle indicazioni sulla necessità di regole che consentano di mantenere l'essere umano al centro.
Certamente c'è da dire che l'intelligenza artificiale, così come la conosciamo oggi, è un vero e proprio spartiacque tecnologico che negli ultimi decenni è stato introdotto.
L'intelligenza artificiale non è una tecnologia ma è una famiglia di tecnologie e possiamo equiparare la sua portata e la sua forza all'energia elettrica, cioè parliamo di tecnologia che è utilizzabile nella più svariata quantità di contesti e che quindi dobbiamo aspettarci sia sempre più diffusa.
Tra il 2023 e il 2024 ai dibattiti hanno fatto seguito anche una serie di atti, di dichiarazioni di carattere generale prese a livello globale dai più diversi organismi.
Il primo fra tutti è il Regolamento Europeo per l'intelligenza artificiale, il Regolamento 1689 del 2024, che è l'unico atto compiutamente vincolante nell'ambito dell'Unione Europea per tutti gli Stati membri e per coloro che erogano servizi all'interno degli Stati membri o che comunque coinvolgono cittadini dell'Unione Europea.
Oltre al Regolamento Europeo abbiamo la Convenzione Quadro sull'intelligenza artificiale del Consiglio d'Europa che è un documento svincolante ma ancora aperto alla sottoscrizione degli Stati membri e poi abbiamo tutta una serie di altre dichiarazioni, ad esempio il report delle Nazioni Unite governing AI for Humanity pubblicato nel luglio 2004, la raccomandazione sull'intelligenza artificiale dell'Ox e che è stata aggiornata nel maggio 2004, il codice di condotta emanato o approvato dai leader del G7, il cosiddetto processo di Hiroshima che dà un quadro per lo sviluppo dell'intelligenza artificiale e interessante anche l'executive order on the safe, secure and trustworthy development and use of AI del novembre 2023 del presidente degli Stati Uniti Biden.
Interessante notare che tutti questi atti hanno delle posizioni condivise che vanno dalla individuazione della necessità che l'intelligenza artificiale abbia una crescita inclusiva, porti a uno sviluppo sostenibile al benessere, la necessità che siano rispettati i diritti umani e i valori democratici, la necessità che la tecnologia sia trasparente e spiegabile, robusta, sicura e protetta, che vi sia la possibilità di individuare come collocare l'assunzione di responsabilità rispetto ad eventuali rischio o danni che possano essere causati, la necessità di formazione di base specialistica e la necessità di cooperazione ad ampio spettro.
Queste sono posizioni condivise che presuppongono e vogliono mantenere l'essere umano al centro.
Quando si parla di essere umano al centro bisogna chiedersi in concreto che cosa questo significhi.
Dobbiamo anche tener conto del fatto che nel parlare di intelligenza artificiale c'è una forte tendenza all'antropomorfizzazione di qualcosa che è tecnologia, proprio perché si teme di perdere il controllo.
Nel corso del tempo diversi studiosi si sono posti il tema, hanno immaginato situazioni nelle quali questa intelligenza artificiale potesse in qualche modo prendere il sopravvento, immaginando una serie di scenari distopici nei quali i robot avranno il sopravvento sull'uomo.
Penso a Max Stegmark che disegnò e individuò 12 diversi scenari nei quali questa fantomatica intelligenza artificiale di volta in volta era comunque considerata una sorta di oracolo, una sorta di Deus ex Machina che poteva avere delle posizioni diverse di asservimento o di predominio rispetto all'essere umano arrivando ad assumere delle decisioni al suo posto.
Al di là di questo tipo di scenari, al di là di questo tipo di preoccupazioni, certo è che per analizzare l'impatto dell'intelligenza artificiale sulla società e progettarne l'utilizzo occorre un approccio multidisciplinare ed è necessario affrontare il tema da diverse prospettive.
Abbiamo la prospettiva della tecnologia, abbiamo la prospettiva delle infrastrutture, abbiamo la prospettiva dei dati utilizzati per l'addestramento, abbiamo la prospettiva del controllo umano fino a che punto possa essere svolto, abbiamo il tema dell'etica e delle regole, abbiamo il tema nelle diverse prospettive, il tema della necessità di etica e regole etiche e giuridiche  e poi c'è un tema di una prospettiva legata alle relazioni internazionali e alle geopolitica perché parliamo di tecnologia che ovviamente è pervasiva e non limitata ad un singolo ambito territoriale e politico, poi abbiamo il tema di chi sono gli attori, di chi interviene nello sviluppo e nell'uso di questi sistemi e poi c'è il tema dell'assunzione delle responsabilità per eventuali danni.
Ho fatto riferimento all'infrastruttore.
Dobbiamo dire che l'intelligenza artificiale si diffonde velocemente e acquista una posizione di predominio perché gran parte dell'infrastruttura necessaria al suo impiego esiste già computer, internet, smartphone, cloud, tutta l'infrastruttura è necessaria e già esistono e quindi questo consente una diffusione estremamente rapida.
Come detto all'inizio l'intelligenza artificiale è una famiglia di tecnologie in evoluzione e non una tecnologia singola.
Se vogliamo cercare di dare una definizione possiamo richiamare l'articolo 3 del regolamento europeo sull'intelligenza artificiale che individua il sistema di intelligenza artificiale come un sistema automatizzato progettato per funzionare con livelli di autonomia variabili che può presentare adattabilità dopo la diffusione e che per obiettivi espliciti o impliciti deduce dall'input che riceve come generare degli output come previsioni, contenuti, raccomandazioni o decisioni che possono influenzare gli ambienti fisici o virtuali.
In questa definizione le keywords di maggior interesse sono l'automatizzazione, l'autonomia variabile, la possibilità di generare output in autonomia e il fatto che tutto ciò può influenzare ambienti fisici o virtuali.
Da questa definizione si comprende come è una buona sintesi di quelle che sono le potenzialità e gli impatti dei sistemi di intelligenza artificiale.
Un modello interessante per gli scopi generali è l'la General Purpose AI Model, cioè un modello di intelligenza artificiale che si è addestrato con grandi quantità di dati utilizzando una supervisione su larga scala caratterizzato da una generalità significativa e in grado quindi di svolgere con competenza un'ampia gamma di compiti distinti, indipendentemente dal modo in cui questo modello è immesso sul mercato e importante che può essere integrato in diversi sistemi o diverse applicazioni e quindi appunto può avere un'ampissima diffusione.
Il dibattito che sta proseguendo su questi temi sta arrivando ad ulteriori valutazioni, una volta che abbiamo individuato che cos'è l'intelligenza artificiale possiamo dire che si tratta veramente di intelligenza nella comparazione con l'intelligenza umana?
Qual è il rapporto tra l'intelligenza artificiale e l'intelligenza umana?
Alla risposta a questa domanda soccorrono soprattutto i filosofi, gli umanisti e quindi si dice che l'intelligenza è conoscenza e amore ad esempio e quindi provare dei sentimenti che l'intelligenza artificiale non prova e poi se manteniamo questa distinzione fra essere umano e intelligenza artificiale dobbiamo domandarci se e fino a che punto possiamo avere dei sistemi che sostituiscono l'essere umano, le valutazioni e le decisioni dell'essere umano.
Considerando anche che le attività degli esseri umani sono composte da una complessità di gesti che presuppone un certo aspetto fisico, una certa fisicità, che presuppone l'uso dei cinque sensi, che presuppone una capacità di manipolazione e che si svolge in un contesto caratterizzato da imprevedibilità, tutte cose possono in qualche modo essere riprodotte dall'intelligenza artificiale ma a patto di inserire tutta una serie di strumenti.
Immaginiamo un robot umanoide, la progettazione e la realizzazione di un braccio umano, della mano che fa delle attività che sono attività che nell'essere umano sono legate comunque anche alla parte  fisica oltre che alla parte mentale per riprodurle con una strumentazione artificiale abbiamo bisogno di software, abbiamo bisogno di hardware, abbiamo bisogno di progettare e di realizzare tutta una serie di parti minime per arrivare a riprodurre quello che è l'attività fisica guidata dalla mente umana dell'essere umano.
Certamente un sistema di intelligenza artificiale può svolgere dei compiti ripetitivi e gestire anche una situazione imprevista se adeguatamente addestrato.
La parte legata all'addestramento, e qui ci stiamo avvicinando al tema dei dati utilizzati per l'addestramento, è essenziale per completare il processo di realizzazione operativa di sistemi dotati dell'intelligenza artificiale.
Al momento perché cosa utilizziamo questi sistemi?
La utilizziamo per l'assistenza ai clienti, customer service, pensiamo alle chatbot o alle voicebot che rispondono in modo tempestivo e accurato alle domande appunto.
Pensiamo all'analisi predittiva ovvero l'analisi di grandi quantità di informazioni che permette di identificare delle tendenze.
Pensiamo alla personalizzazione di servizi in particolare se erogati online che sono mirati sulle necessità individuali.
Pensiamo all'automazione dei processi, ma pensiamo anche a situazioni che hanno un impatto forte proprio sull'essere umano come la gestione delle risorse umane, quindi la selezione, il reclutamento, la valutazione della performance.
Pensiamo a situazioni nelle quali si ha come obiettivo la prevenzione di frodi, analizzando una serie di pratiche, di situazioni che vengono prese in considerazione per uno specifico ente.
Ma pensiamo anche al forte impatto sull'essere umano dato dalla possibilità di analizzare i dati provenienti dai social media o dalle recensioni online o dalle altre fonti, quello che si chiama la cosiddetta analisi del sentiment, o ancora alla medicina personalizzata e quindi alla possibilità di fare diagnosi personalizzate basate su informazioni precedenti ma che vanno veramente ad identificare anche dei trattamenti personalizzati.
Questi sono esempi per i quali l'intelligenza artificiale viene effettivamente utilizzata al giorno d'oggi, che hanno un impatto sul mondo circostante.
I settori più sensibili nei quali l'intelligenza artificiale viene utilizzata è il settore delle risorse umane, il settore della giustizia, il settore della sicurezza e della difesa, il settore della sanità e il settore dell'informazione.
Questi sono gli ambiti nei quali maggiormente c'è un impatto sul contesto sugli esseri umani.
E se dobbiamo vedere l'impatto dobbiamo anche pensare alla fase di addestramento e dobbiamo anche pensare che l'impatto potrebbe essere determinato da un addestramento non fatto bene, che porti con sé preconcetti, bias, che in qualche modo possono influenzare anche pesantemente le conclusioni e l'utilizzo di questi sistemi.
Normalmente vengono citati alcuni casi famosi, uno era il caso così detto caso Loomis di un algoritmo che era stato utilizzato da tribunali americani per valutare il rischio di recidivia delle persone condannate, rispetto al quale si assumeva che fossero stati assorbiti dei preconcetti legati all'appartenenza ad una specifica razza, oppure un altro caso che prendeva in considerazione l'erogazione di mutui, che prendendo come indicazioni i mutui erogati in precedenza, sulla base della rilevazione del fatto che in determinati quartieri c'era una minore presenza di correntisti o di destinatari di mutui, aveva portato all'elaborazione di un preconcetto per cui persone appartenenti a un determinato quartiere non erano in condizioni di essere finanziate.
Quindi i preconcetti che possono informare l'intelligenza artificiale sono dei preconcetti che nascono dall'analisi dei dati che vengono utilizzati per l'addestramento e che se non valutati adeguatamente e non gestiti con delle misure di mitigazione possono poi avere un impatto a cascata sulla presentazione, sull'erogazioni dei servizi, sulle attività, sulle decisioni che vengono assunte dal sistema automatizzato anziché dall'essere umano.
Altro tema è quello legato alla responsabilità, cioè se il mutuo non viene erogato ad una persona perché c'è un bias, la responsabilità di chi è, di chi ha progettato il sistema, di chi lo ha addestrato, della banca che lo ha utilizzato.
Ecco qua si introduce quello che è noto come il problema della responsabilità delle molte mani.
Il fatto che lo sviluppo e il funzionamento dell'intelligenza artificiale comporti in generale contributi da parte di più persone, più organizzazioni, più componenti porta a doversi porre il problema a monte di chi dove deve assumersi la responsabilità.
Su questo argomento il regolamento europeo per l'intelligenza artificiale inizia a fornire delle risposte e in linea generale si dice che chiunque in qualche modo intervenga assume la propria parte di responsabilità. Si dice che, e questo è un approccio che viene utilizzato da tutti i regolamenti europei dal 2016 in poi, che chi utilizza il sistema deve fare una preventiva valutazione di impatto, deve fare un risk assessment e deve quindi cercare di analizzare quali possono essere gli impatti negativi del sistema che utilizza e mitigarlo con delle misure preventive.
Il tema della distribuzione delle responsabilità è più forte quando, come nella maggior parte dei casi succede, non si parla solo di sistemi automatizzati ma si parla di situazioni nelle quali vi è un'interazione tra gli esseri umani e gli strumenti digitali.
In questi casi la difficoltà di ripartire correttamente le responsabilità è più complessa, quindi da un lato riteniamo che sia necessario che l'essere umano rimanga al centro nel controllo delle attività, dall'altro però dobbiamo renderci conto che questo fa sì che l'attribuzione di responsabilità diventa più complessa.
Pensiamo all'utilizzo di un veicolo autonomo, se il veicolo è completamente automatico e viaggia su una strada in cui ci sono solo veicoli automatici, la gestione del rischio e l'adozione delle decisioni è lasciata esclusivamente alla macchina, ma se l'essere umano può prendere il controllo a quel punto interviene la necessità di un'assunzione di responsabilità anche da parte dell'essere umano, il quale a un certo punto decide di intervenire e come intervenire.
Quindi la valutazione dell'impatto che può essere fatta preventivamente deve in realtà poi essere integrata di volta in volta con le valutazioni delle situazioni concrete in cui ci si trova.
Vorrei ancora dire che in questo contesto abbiamo un forte gap di genere.
Nonostante le donne rappresentino il 51\% della popolazione dell'Unione Europea abbiamo solo un laureato su tre in discipline STEM, solo una specialista su cinque nel settore dei CT che sono di genere femminile.
Questo non è una affermazione che faccio, non è una informazione che do soltanto per una questione di correttezza di rapporto di genere, ma anche perché inevitabilmente la presenza di entrambi i generi può avere delle conseguenze, proprio un impatto, sia nello sviluppo che nell'utilizzo, perché ognuno porta con sé una propria modalità, un proprio approccio non solo culturale e questo vale non soltanto per il genere ma  anche per le nazionalità di coloro che intervengono e quindi è importante tenerne conto per evitare che questi gap si riproducano come bias nello sviluppo e nell'utilizzo dei sistemi.
Principi dell'AI Act che come abbiamo detto è il primo quadro giudico vincolante. L'impostazione è quella per cui occorre un'analisi del rischio e una valutazione da parte di chi utilizza, considerando che sono stati indicati diverse tipologie di rischi in base ai quali vengono previste delle misure di intervento, di mitigazione e quindi nel caso in cui il rischio si ritenga inaccettabile non è possibile utilizzare sistemi di intelligenza artificiale. Mano a mano che si passa da un rischio elevato a un rischio limitato ci sono delle cautele da adottare, se il rischio è minimo invece è possibile sviluppare senza difficoltà.
Passiamo quindi al tema dei dati.
I dati sono sostanzialmente il carburante indispensabile per l'intelligenza artificiale, per l'addestramento e il funzionamento dell'intelligenza artificiale.
L'Unione Europea ha elaborato e dato una strategia per l'intelligenza artificiale che è ritenuta fondamentale per lo sviluppo dell'essere umano, ha elaborato anche una strategia per i dati.
Consideriamo che un agente intelligente ha bisogno di un modello interno del suo ambiente per scegliere le proprie azioni e prendere le decisioni.
Il modello è creato da un algoritmo partendo dai dati e permette di stimare la probabilità di eventi ricorrenti contandole la frequenza in passato la cosiddetta previsione.
Tutti gli agenti che interagiscono con l'ambiente raccolgono dati da punti più diversi.
Nel regolamento europeo per l'intelligenza artificiale si parla di dati di addestramento, facendo riferimento ai dati utilizzati per addestrare un sistema di intelligenza artificiale adattando i parametri che questo sistema può apprendere.
Più un modello è complesso più sono i dati richiesti per addestrarlo e aumentare le dimensioni dei modelli di linguaggio ne migliora le capacità di apprendere nuovi compiti con rapidità, ma un modello addestrato con dati di cattiva qualità produce risultati di cattiva qualità, un modello che prende i dati dal mondo circostante assorbe i bias di chi produce i dati e un modello non raffinato può produrre quelle che vengono in gergo chiamate allucinazioni e che sono sostanzialmente degli errori.
Sulla quantità dei dati torniamo invece a un tema di cui si è discusso per tanto tempo che è quello dei big data.
Considerate che per addestrare GPT-3 è stato necessario un corpus di circa di 500 gigabyte, 500 miliardi di parole, che sono state prese dando impasto ai sistemi, 12 miliardi di stringe di libri, 3 miliardi di Wikipedia, 19 miliardi di web test, cioè la quantità di dati non raffinati utilizzati per l'addestramento del sistema è stata enorme.
Parliamo di dati però presi da ovunque, quindi di dati non raffinati sui quali non c'è alcun tipo di controllo e che quindi consentono al sistema di rispondere anche a caso, cioè la raccolta, la verifica, il controllo delle informazioni è lasciato al sistema e quindi è per questo che poi quando un sistema deve essere utilizzato in contesti specifici è necessario comunque raffinare l'addestramento con dei dati di qualità.
Mentre l'acquisizione di dati attraverso agenti che interagiscono con l'ambiente è relativamente economica, il raffinamento con dati di qualità che richiede un intervento di tipo diverso ha invece dei costi molto più elevati.
Il tema dei costi è un tema importantissimo nello sviluppo della tecnologia e dell'intelligenza artificiale..
C'è un'interessantissima mappa della frequenza di uso dei data set in base ai diversi paesi e notiamo che in questa mappa i paesi del cosiddetto nord del mondo hanno un uso di dati, di ricerca di dati ma anche di produzione di dati molto più elevato di quello che hanno i paesi del cosiddetto sud del mondo.
L'America del nord in questa rappresentazione ha un consumo enorme.
Questo porta a un impatto non soltanto sull'utilizzo ma in realtà anche un impatto sull'addestramento perché i dati che noi mettiamo nell'ambiente, quindi dati che provengono sono anche dati che veicolano abitudini, sistemi culturali, approcci e quindi questo vuol dire che un sistema di intelligenza artificiale addestrato su questa vasta scala di dati raccolti da ovunque avrà la tendenza a comportarsi come loro che sono all'interno, che sono in quel determinato paese e quindi la complessità nell'utilizzare alcuni sistemi nel contesto italiano ad esempio, nei progetti di giustizia per esempio, sta anche nel fatto che il preaddestramento del sistema si basa su dati prodotti in paesi diversi con cultura diversa e con sistemi giudiziari giudici diversi e quindi se devo predisporre un sistema per la giustizia predittiva basato su un addestramento fatto con dati degli Stati Uniti, prevalentemente del Nord America, dovrò raffinarlo considerando proprio le differenze dei sistemi, le differenze di linguaggio, ci sarà un tema di traduzione, ci sarà un tema di apprensione dei sistemi giudici diversi, ci sarà un tema di acquisizione di cultura diversa da quella a cui si è normalmente abituati, quindi ci sarà la necessità di un lavoro molto impegnativo.
Per quanto riguarda l'Europa, come detto i dati sono al centro della trasformazione, l'Unione Europea ha elaborato una vera e propria strategia dei dati considerando che attualmente l'80\% dei dati europei, non parliamo di dati personali ma di dati industriali, non è stato utilizzato a causa della diffidenza nella condivisione di dati, a causa di ostacoli economici e tecnologici e quindi si è elaborata tutta una serie, un set normativo, un set di regole volte a consentire una più semplice diffusione e riutilizzo dei dati, in particolare dei dati pubblici o di interesse pubblico.

Le regole che sono state elaborate sono delle regole che riguardano i dati detenuti da enti pubblici o i dati detenuti dai privati, oltre che i dati personali di cui già sappiamo, sono regole che si occupano della possibilità di riutilizzare questi dati gratuitamente o a pagamento, sono regole che si occupano di tutelare le piccole imprese europee che sono la maggioranza e quindi mentre abbiamo in altri paesi le cosiddette big tech in Europa abbiamo soprattutto piccole e medie imprese e quindi l'obiettivo è tutelarle rispetto alle posizioni dominanti delle big tech. Poi queste regole si occupano  di tutelare i diritti delle persone come fonte di dati, sistemi che apprendono dalle interazioni, le interazioni  rispetto i dati messi in rete, possono essere dati messi in rete dall'essere umano e così via, ma che tutelano le persone come fonte di dati ma anche come utenti dei dati che vengono prodotti dalle macchine, dalle apparecchiature che vengono utilizzate.
L'obiettivo è favorire la circolazione e riuso di dati reali, rendere disponibili gratis dati pubblici per finalità pubbliche e consentire la commercializzazione dei dati privati.
Questa strategia ha cinque pilastri e sono in fase di elaborazione altri pilastri settoriali, quindi abbiamo innanzitutto il GDPR, il General Data Protection Regulation ovvero il regolamento 2016 del numero 679, il primo, poi abbiamo una direttiva, la cosiddetta direttiva open data che si occupa del riuso dei dati pubblici ed è del 2019, poi abbiamo il Data Governance Act del 2022 che si occupa della condivisione volontaria dei dati, diversi dai dati personali e poi abbiamo il Data Act del 2023.
Il Data Act riguarda la creazione di valore da dati prodotti dai sistemi che vengono utilizzati e poi l'ultimo nato nel 2024 è il regolamento europeo per l'intelligenza artificiale che presuppone comunque l'uso di dati.
Al momento l'Unione Europea sta elaborando norme per l'individuazione di spazi europei di dati in settori specifici, tra questi è particolarmente interessante lo spazio europeo dei dati sanitari rispetto al quale nel corso dell'estate 2024 è stato raggiunto un accordo politico. Quindi il tema è quello di costruire uno spazio sicuro in cui sia possibile condividere e riutilizzare i dati rispettando comunque i diritti delle persone, vuoi per quanto riguarda la tutela dei dati personali, vuoi per quanto riguarda la tutela di altri diritti come la proprietà intellettuale, il segreto industriale, il segreto di stato e quindi tutta la declinazione dei vari diritti di cui occorre tenere in conto quando si svolgono queste attività.


Un ultimo spunto importante è che tutto questo richiede anche una forte attenzione alla sicurezza informatica, alla cyber sicurezza.
Viaggiamo e siamo su spazi di condivisione di dati, viaggiamo su sistemi tecnologici, la cyber sicurezza è essenziale; Quando parliamo di cyber sicurezza parliamo sia di misure tecnologiche di sicurezza ma anche di sviluppo di politiche e procedure organizzative che sono il presupposto necessario o comunque sono complementari alla gestione corretta della sicurezza informatica.

Il regolamento è un regolamento europeo e quindi i regolamenti europei sono norme adottate dall'Unione Europea che sono immediatamente vincolanti quindi sono obbligatorie per tutti gli stati membri e quindi anche per l'Italia.
Questo regolamento dei IAEA è stato adottato nel luglio del 2024 e prevede due anni per l'adeguamento concreto perché le regole sono già vincolanti per tutti.
Nonostante questo, l'Italia ha comunque deciso di predisporre una propria norma nazionale che ovviamente non può andare in nessun modo in contrasto con le previsioni del regolamento e che tenta di aggiungere qualche cosa ma soprattutto ha come obiettivo quello di individuare le autorità competenti in Italia per la regolamentazione.
Quindi le regole giuridiche sono quelle e i vincoli dati sono quelli.
Dopodiché il problema sarà concretizzare lo sviluppo di sistemi che rispettino quelle regole e per valutare se i sistemi sono sviluppati in maniera adeguata, occorrerà che ogni paese deve nominare un'autorità competente che avrà il compito proprio di fare un monitoraggio, di dare delle risposte, di verificare se i sistemi sviluppati sono compliant con le regole europee.
Dopodiché come detto c'è un principio per cui è la stessa impresa che importa, che utilizza o che produce a doversi fare carico delle valutazioni di correttezza dei sistemi che produce o che utilizza quindi è in qualche modo c'è un'attività collaborativa per lo sviluppo di questi sistemi.


Non è soltanto il rispetto della regola ma c'è anche un altro aspetto da considerare che le regole che sono scritte sono delle regole comunque teoriche e nel momento in cui si sviluppa qualcosa di concreto occorre poi effettivamente comprendere come realizzare gli oggetti.

Quindi torna in maniera pesante e preponderante il problema affrontato in precedenza delle fake news che hanno oltre ai bias che possono essere presenti nella raffinazione dei dati ma anche il fatto che ci siano alla fonte informazioni sbagliate in partenza.
Questo è un tema però quando parliamo di dati raccolti dalla rete dobbiamo anche tenere in mente i dati scambiati da altri tipi di apparecchiature, non pensiamo soltanto alle comunicazioni, ciò che viene scritto nei blog, nelle chat, etc.
Pensiamo anche all'internet of things e quindi a tutti i dati che vengono trasferiti dai vari strumenti che sono collegati.
Il tema della raccolta del rischio di addestramento di portarsi dentro dei bias non è solo legato alle fake news, è legato in generale proprio alla enorme quantità di dati che provengono dalle fonti più disparate.
Tra l'altro potrebbe anche avere un impatto al di là dei dati che riguardano le persone, immaginiamo uno strumento non tarato bene per la rilevazione del tempo.
Noi abbiamo in mente il tema delle fake news perché pensiamo, e giustamente è uno degli aspetti di sensibilità maggiore, pensiamo ai dati legati alle comunicazioni fra persone, però c'è tutto il mondo dei dati raccolti utilizzati nell'ambito dell'agricoltura, per i terremoti, per quindi tutto quello che è il contesto dell'ambiente.
E poi quando si parla dei dati sanitari parliamo dei dati legati alle diagnosi, quindi dati parcellizzati, legati alla ricerca scientifica, che sono qualcosa di diverso e che però hanno anchessi un impatto.
L'uso di questi dati ha comunque un impatto molto forte.